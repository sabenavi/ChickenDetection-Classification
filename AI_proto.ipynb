{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrebase\n",
    "#from firebase_admin import credentials, storage,initialize_app\n",
    "import streamlit as st\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from time import time\n",
    "import os\n",
    "import datetime as dt\n",
    "import glob\n",
    "import imageio \n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import squeezenet1_1\n",
    "from torchvision.transforms.transforms import RandomHorizontalFlip\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import pathlib\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        self.fc2 = nn.Linear(500, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # se agrega las capaz convolucionales y de max pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = self.dropout(x)\n",
    "        #se agrega primera capa con funcion de activacion ReLu\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # se agrega capa de dropout\n",
    "        x = self.dropout(x)\n",
    "        # se agrega otra capa de funcion de activación ReLu\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class ChickenDetection:\n",
    "    def __init__(self, model_name):\n",
    "        self.model=self.load_model(model_name)\n",
    "        self.classes = self.model.names\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(\"Device used: \",self.device)\n",
    "    def load_model(self, model_name):\n",
    "        if model_name:\n",
    "            model = torch.hub.load('ultralytics/yolov5','custom',path=model_name, force_reload = True)\n",
    "        else:\n",
    "            model = torch.hub.load('ultralytics/yolov5','yolo5s',pretrained=True)\n",
    "        return model\n",
    "    \n",
    "    def score_frame(self, frame):\n",
    "        self.model.to(self.device)\n",
    "        frame=[frame]\n",
    "        results = self.model(frame)\n",
    "        labels, cord = results.xyxyn[0][:, -1] , results.xyxyn[0][:, :-1] \n",
    "        return labels, cord\n",
    "    \n",
    "    def class_to_label(self, x):\n",
    "        return self.classes[int(x)]\n",
    "    \n",
    "    def plot_boxes(self, results, frame):\n",
    "        labels, cord= results\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "        path_write_im = 'C:\\\\Users\\\\sheyl\\\\Documentos\\\\frames_labeled\\\\'\n",
    "        cord_l= []\n",
    "        c=0\n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            if row[4] >= 0.3:\n",
    "                c+=1\n",
    "                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "                bgr = (0,255,0)\n",
    "                print('x1: {}, y1: {} , x2: {} , y2: {}'.format(x1,y1,x2,y2))\n",
    "                imageRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                pil_img = Image.fromarray(imageRGB[y1:y2,x1:x2]) # convert opencv frame (with type()==numpy) into PIL Image\n",
    "                pil_img.save(path_write_im+dt.datetime.now().strftime('IMG-%Y-%m-%d-%H%M%S')+str(c)+'.jpg')\n",
    "            cord_l.append([row[0],row[1],row[2],row[3]])\n",
    "        print(cord_l)\n",
    "        return frame\n",
    "    \n",
    "    \n",
    "    def __call__(self):\n",
    "        \n",
    "        for file in glob.glob(path+'*.jpg'):\n",
    "            fr = cv2.imread(file)\n",
    "            fr = cv2.resize(fr, (420,420))\n",
    "            results = self.score_frame(fr)\n",
    "            fr_n= self.plot_boxes(results,fr)\n",
    "            print('Detected: {}'.format(file))\n",
    "        classes=[\"healthy\",\"sick\"]\n",
    "        transform = transforms.Compose([\n",
    "            \ttransforms.Resize((32,32)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                ])\n",
    "        def prediction(img_path,transformer):\n",
    "            image = Image.open(img_path)\n",
    "            image_tensor = transformer(image).float()\n",
    "            image_tensor = image_tensor.unsqueeze_(0)\n",
    "            if torch.cuda.is_available():\n",
    "                image_tensor.cuda()\n",
    "            input=Variable(image_tensor)\n",
    "            output = model(input)\n",
    "            index = output.data.numpy().argmax()\n",
    "            pred = classes[index]\n",
    "            return pred\n",
    "        check= torch.load('C:\\\\Users\\\\sheyl\\\\Documentos\\\\'+'model_chicken_classification.pt')\n",
    "        model = Net()\n",
    "        model.load_state_dict(check)\n",
    "        model.eval()\n",
    "\n",
    "        path_read = 'C:\\\\Users\\\\sheyl\\\\Documentos\\\\frames_labeled\\\\'\n",
    "        pred_dict = {}\n",
    "        #count_bar = 0\n",
    "        c=0\n",
    "        st.title(\"Detección de enfermedades:\")\n",
    "        with st.spinner(\"Analizando video:\"):\n",
    "            for file in glob.glob(path_read+'*.jpg'):\n",
    "                #count_bar+=1\n",
    "                #st.progress(count_bar)\n",
    "                if (prediction(file,transform)==\"sick\"):\n",
    "                    c+=1\n",
    "                    storage.child(\"sick_\"+str(c)+'.jpg').put(file)\n",
    "                    pred_dict[file[file.rfind('/')+1:]]=prediction(file,transform)\n",
    "                    imageRGB2 = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB)\n",
    "                    pil_img2 = Image.fromarray(imageRGB2) # convert opencv frame (with type()==numpy) into PIL Image\n",
    "                    st.image(pil_img2,channels = 'BGR')\n",
    "            for file in os.listdir(path_read):\n",
    "                if file.endswith('.jpg'):\n",
    "                    os.remove(file) \n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.jpg'):\n",
    "                    os.remove(file)\n",
    "            if len(pred_dict)>0:\n",
    "                st.error(\"Detección finalizada.\"+ \" Número de pollos enfermos detectados: \"+str(len(pred_dict)))\n",
    "            else:\n",
    "                st.success(\"No se han detectado pollos enfermos\")\n",
    "            print(pred_dict)\n",
    "        \n",
    "config = {\n",
    "\n",
    "  \"apiKey\": \"AIzaSyBbyQG38gxGhuGtQCVPlCEoQSSyt5yD0PQ\",\n",
    "\n",
    "  \"authDomain\": \"smartstorage-a6197.firebaseapp.com\",\n",
    "\n",
    "  \"databaseURL\": \"https://smartstorage-a6197-default-rtdb.firebaseio.com\",\n",
    "\n",
    "  \"projectId\": \"smartstorage-a6197\",\n",
    "\n",
    "  \"storageBucket\": \"smartstorage-a6197.appspot.com\",\n",
    "\n",
    "  \"serviceAccount\": \"key.json\"\n",
    "\n",
    "}\n",
    "\n",
    "firebase_storage = pyrebase.initialize_app(config)\n",
    "storage = firebase_storage.storage()\n",
    "    \n",
    "    \n",
    "uploaded_video = st.file_uploader(\"Subir video\", type=[\"mp4\", \"mov\"])\n",
    "frame_skip = 300 # display every 300 frames\n",
    "\n",
    "if uploaded_video is not None: # run only when user uploads video\n",
    "    vid = uploaded_video.name\n",
    "    with open(vid, mode='wb') as f:\n",
    "        f.write(uploaded_video.read()) # save video to disk\n",
    "\n",
    "    st.title(\"Cámara\")\n",
    "    video_file = open(vid,'rb')\n",
    "    video_bytes = video_file.read()\n",
    "    st.video(video_bytes)\n",
    "    vidcap = cv2.VideoCapture(vid) # load video from disk\n",
    "    cur_frame = 0\n",
    "    success = True\n",
    "    path = 'C:\\\\Users\\\\sheyl\\\\Documentos\\\\frames\\\\'\n",
    "\n",
    "    while success:\n",
    "        success, frame = vidcap.read() # get next frame from video\n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "        minutes = 0\n",
    "        seconds = 5\n",
    "        frame_id = int(fps*(minutes*60 + seconds))\n",
    "        print('fps: {}'.format(fps))\n",
    "        print('frame_id: {}'.format(frame_id))\n",
    "        if cur_frame % frame_id == 0: \n",
    "            print('frame: {}'.format(cur_frame))\n",
    "            #Guarda la imagen de la frame en el tiempo indicado\n",
    "            imageRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_img = Image.fromarray(imageRGB) \n",
    "            pil_img.save(path+dt.datetime.now().strftime('IMG-%Y-%m-%d-%H%M%S')+'.jpg')\n",
    "            cur_frame = 0\n",
    "        cur_frame += 1\n",
    "    yolo_detection = ChickenDetection(model_name='C:\\\\Users\\\\sheyl\\\\Documentos\\\\'+'last.pt')\n",
    "    yolo_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
